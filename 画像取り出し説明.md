# Pukiwiki画像ダウンローダー - 画像取り出し処理詳細説明

## 概要
このドキュメントでは、Pukiwiki画像ダウンローダーが`<img>`タグから画像URLを抽出する処理について詳しく説明します。

## 処理の全体的な流れ

1. **HTMLページの取得**
2. **BeautifulSoupでHTML解析**
3. **全ての`<img>`タグの検索**
4. **各`<img>`タグからsrc属性の抽出**
5. **相対URLの絶対URL変換**
6. **画像ファイルの判定**
7. **画像URLリストの作成**

## 主要な処理メソッド

### `extract_images_from_page(page_url)`

このメソッドが画像抽出処理の中心となります。

```python
def extract_images_from_page(self, page_url):
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        # HTMLページを取得
        response = requests.get(page_url, headers=headers, timeout=30)
        response.raise_for_status()
        
        # BeautifulSoupでHTML解析
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # 全ての<img>タグを検索
        img_tags = soup.find_all('img')
        image_urls = []
        
        for img in img_tags:
            src = img.get('src')
            if src:
                # 相対URLを絶対URLに変換
                full_url = urljoin(page_url, src)
                
                # 画像ファイルかどうかの判定
                if self.is_image_file(full_url):
                    image_urls.append(full_url)
                    
        return image_urls
        
    except Exception as e:
        self.log_message(f"画像抽出エラー {page_url}: {str(e)}")
        return []
```

## 処理の詳細説明

### 1. HTMLページの取得

```python
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
}

response = requests.get(page_url, headers=headers, timeout=30)
response.raise_for_status()
```

- **User-Agentヘッダー**: ブラウザを模倣してサーバーからの適切なレスポンスを得る
- **タイムアウト設定**: 30秒でタイムアウトしてハングアップを防ぐ
- **エラーハンドリング**: `raise_for_status()`でHTTPエラーを例外として扱う

### 2. BeautifulSoupによるHTML解析

```python
soup = BeautifulSoup(response.content, 'html.parser')
```

- **html.parser**: 標準のHTMLパーサーを使用
- **HTMLコンテンツの構造化**: DOMツリーとして解析し、要素へのアクセスを可能にする

### 3. `<img>`タグの検索と抽出

```python
img_tags = soup.find_all('img')

for img in img_tags:
    src = img.get('src')
    if src:
        # 処理続行
```

- **`find_all('img')`**: ページ内の全ての`<img>`タグを取得
- **`img.get('src')`**: 各`<img>`タグの`src`属性を安全に取得
- **None値チェック**: `src`属性が存在しない場合をスキップ

### 4. 相対URLの絶対URL変換

```python
full_url = urljoin(page_url, src)
```

- **urljoin関数**: 元のページURLと相対パスを結合して完全なURLを生成
- **例**:
  - `page_url`: `http://example.com/pukiwiki/page.php`
  - `src`: `images/photo.png`
  - `full_url`: `http://example.com/pukiwiki/images/photo.png`

### 5. 画像ファイルの判定

Pukiwiki特有の画像URL形式に対応した3つの判定パターン：

#### パターン1: 通常の画像URL
```python
if re.search(r'\.(png|jpg|jpeg)(\?.*)?$', full_url, re.IGNORECASE):
    is_image = True
```
- **対象**: `http://example.com/images/photo.png`
- **対象**: `http://example.com/images/photo.jpg?v=123`

#### パターン2: Pukiwikiの`src=`パラメータ形式
```python
elif re.search(r'[?&]src=[^&]*\.(png|jpg|jpeg)', full_url, re.IGNORECASE):
    is_image = True
```
- **対象**: `http://example.com/pukiwiki/?src=image.png`
- **対象**: `http://example.com/pukiwiki/?cmd=view&src=photo.jpg`

#### パターン3: Pukiwikiプラグイン形式
```python
elif re.search(r'(plugin=attach|plugin=ref).*\.(png|jpg|jpeg)', full_url, re.IGNORECASE):
    is_image = True
```
- **対象**: `http://example.com/pukiwiki/?plugin=attach&file=image.png`
- **対象**: `http://example.com/pukiwiki/?plugin=ref&src=photo.jpg`

## 特殊な処理とフィルタリング

### スキップされる画像パターン
以下のファイル名パターンは自動的にスキップされます：

```python
self.skip_patterns = [
    'backup_*.png', 'copy_*.png', 'diff_*.png', 'edit_*.png',
    'file_*.png', 'freeze_*.png', 'help_*.png', 'index_*.png',
    'list_*.png', 'new_*.png', 'pukiwiki_*.png', 'recentchanges_*.png',
    'reload_*.png', 'rename_*.png', 'rss_*.png', 'search_*.png',
    'smile_*.png', 'top_*.png', 'unfreeze_*.png'
]
```

### ファイル名の抽出方法

```python
def extract_filename_from_url(self, img_url):
    # Pukiwiki形式のURL（src=ファイル名）から抽出
    src_match = re.search(r'[?&]src=([^&]*\.(png|jpg|jpeg))', img_url, re.IGNORECASE)
    if src_match:
        return src_match.group(1)
    
    # openfile=ファイル名の形式から抽出
    openfile_match = re.search(r'[?&]openfile=([^&]*\.(png|jpg|jpeg))', img_url, re.IGNORECASE)
    if openfile_match:
        return openfile_match.group(1)
    
    # 通常のURL形式からファイル名を取得
    parsed_url = urlparse(img_url)
    filename = os.path.basename(parsed_url.path)
    
    # ファイル名が適切でない場合
    if not filename or '.' not in filename:
        extension = '.png' if 'png' in img_url.lower() else '.jpg'
        timestamp = int(time.time())
        filename = f"image_{timestamp}{extension}"
    
    return filename
```

## エラーハンドリング

### 処理例外の捕捉
```python
try:
    # 画像抽出処理
    pass
except Exception as e:
    self.log_message(f"画像抽出エラー {page_url}: {str(e)}")
    return []
```

### 一般的なエラーケース
1. **ネットワークエラー**: タイムアウト、接続エラー
2. **HTMLパースエラー**: 不正なHTMLコンテンツ
3. **URLエラー**: 無効なURL形式
4. **権限エラー**: アクセス拒否されたページ

## 実行例

### 入力
```
page_url = "http://example.com/pukiwiki/?PageName"
```

### 処理結果
```
image_urls = [
    "http://example.com/pukiwiki/images/photo1.png",
    "http://example.com/pukiwiki/?plugin=attach&file=diagram.jpg",
    "http://example.com/pukiwiki/?src=screenshot.png"
]
```

### ログ出力例
```
[14:30:15] ページ処理開始: http://example.com/pukiwiki/?PageName
[14:30:16] 画像を発見: photo1.png
[14:30:16] 画像を発見: diagram.jpg
[14:30:16] 画像を発見: screenshot.png
[14:30:16] 画像抽出完了: 3個の画像URL取得
```

## 技術的な特徴

### 使用ライブラリ
- **requests**: HTTP通信
- **BeautifulSoup4**: HTML解析
- **re**: 正規表現処理
- **urllib.parse**: URL操作

### パフォーマンス配慮
- **タイムアウト設定**: 長時間の待機を防止
- **例外処理**: 個別エラーで全体処理を停止しない
- **メモリ効率**: 大量の画像URLを効率的に処理

### セキュリティ配慮
- **User-Agentヘッダー**: 適切なブラウザ識別
- **リファラーヘッダー**: ダウンロード時の元ページ情報送信
- **タイムアウト**: DoS攻撃の回避

## まとめ

この画像抽出処理は、Pukiwikiの特殊なURL形式に対応した堅牢な実装となっています。通常のWebページだけでなく、Pukiwikiの動的な画像生成機能にも対応し、エラーハンドリングも充実しているため、実用的な画像一括ダウンロードが可能です。 